# LangChain 1.x å¤šä»»åŠ¡é—®ç­”åŠ©æ‰‹ - ä¼ä¸šçº§æ¶æ„æ–‡æ¡£

> **ç‰ˆæœ¬**: 1.0.0
> **æ›´æ–°æ—¥æœŸ**: 2025-01-02
> **æŠ€æœ¯æ ˆ**: LangChain >= 1.0 + Python 3.10+
> **æ¶æ„æ¨¡å¼**: æ™ºèƒ½ä½“ (Agent) + å·¥å…·è°ƒç”¨ (Tool Calling)
>
> **é‡è¦è¯´æ˜**: æœ¬é¡¹ç›®åŸºäº LangChain v1.x æ„å»ºï¼Œè¦æ±‚ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [æ ¸å¿ƒæ¶æ„](#2-æ ¸å¿ƒæ¶æ„)
3. [æŠ€æœ¯æ ˆä¸ä¾èµ–](#3-æŠ€æœ¯æ ˆä¸ä¾èµ–)
4. [é¡¹ç›®ç»“æ„](#4-é¡¹ç›®ç»“æ„)
5. [LangChain 1.x æ ¸å¿ƒç‰¹æ€§](#5-langchain-1x-æ ¸å¿ƒç‰¹æ€§)
6. [ä¼ä¸šçº§æœ€ä½³å®è·µ](#6-ä¼ä¸šçº§æœ€ä½³å®è·µ)
7. [éƒ¨ç½²ä¸è¿ç»´](#7-éƒ¨ç½²ä¸è¿ç»´)
8. [æ€§èƒ½ä¼˜åŒ–](#8-æ€§èƒ½ä¼˜åŒ–)
9. [å®‰å…¨ä¸åˆè§„](#9-å®‰å…¨ä¸åˆè§„)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 ä¸šåŠ¡èƒŒæ™¯

æœ¬é¡¹ç›®æ˜¯**ä¼ä¸šçº§å¤šä»»åŠ¡æ™ºèƒ½é—®ç­”åŠ©æ‰‹**ï¼ŒåŸºäº LangChain 1.x æ¡†æ¶æ„å»ºï¼Œé‡‡ç”¨ç°ä»£åŒ–çš„ Agent æ¶æ„æ¨¡å¼ã€‚ç³»ç»Ÿé€šè¿‡æ™ºèƒ½å·¥å…·è°ƒç”¨å®ç°å¤šåœºæ™¯é—®ç­”èƒ½åŠ›ï¼Œé€‚ç”¨äºä¼ä¸šå†…éƒ¨çŸ¥è¯†åº“ã€å®¢æˆ·æœåŠ¡ã€æ™ºèƒ½åŠ©æ‰‹ç­‰åœºæ™¯ã€‚

### 1.2 æ ¸å¿ƒèƒ½åŠ›

#### æ™ºèƒ½å¯¹è¯èƒ½åŠ›
- âœ… åŸºäº GPT-4/GPT-3.5 çš„è‡ªç„¶è¯­è¨€ç†è§£
- âœ… ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¤šè½®å¯¹è¯
- âœ… æ„å›¾è¯†åˆ«ä¸æ§½ä½å¡«å……
- âœ… æµå¼è¾“å‡ºä¸å®æ—¶å“åº”

#### å·¥å…·é›†æˆèƒ½åŠ›
- ğŸŒ¤ï¸ **å¤©æ°”æŸ¥è¯¢**: é«˜å¾·åœ°å›¾ API å®æ—¶å¤©æ°”æ•°æ®
- ğŸ” **æ™ºèƒ½æœç´¢**: Tavily AI æœç´¢å¼•æ“é›†æˆ
- ğŸ“Š **æ•°æ®æŸ¥è¯¢**: å¯æ‰©å±•çš„æ•°æ®æºè¿æ¥å™¨
- ğŸ”§ **å·¥å…·è·¯ç”±**: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å·¥å…·

#### ä¼ä¸šçº§ç‰¹æ€§
- ğŸš€ **é«˜æ€§èƒ½**: å¼‚æ­¥å¤„ç† + Redis ç¼“å­˜
- ğŸ“Š **å¯è§‚æµ‹**: å®Œæ•´çš„æ—¥å¿—ä¸ç›‘æ§ä½“ç³»
- ğŸ” **å®‰å…¨æ€§**: API å¯†é’¥ç®¡ç† + è®¿é—®æ§åˆ¶
- ğŸ“ˆ **å¯æ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºé›†æˆæ–°å·¥å…·

### 1.3 æŠ€æœ¯äº®ç‚¹

```mermaid
graph TB
    A[ç”¨æˆ·è¾“å…¥] --> B[LangChain Agent]
    B --> C{æ„å›¾è¯†åˆ«}
    C -->|å¤©æ°”æŸ¥è¯¢| D[é«˜å¾·å¤©æ°”å·¥å…·]
    C -->|ä¿¡æ¯æœç´¢| E[Tavilyæœç´¢å·¥å…·]
    C -->|æ™®é€šå¯¹è¯| F[LLMç›´æ¥å›ç­”]
    D --> G[å“åº”ç”Ÿæˆ]
    E --> G
    F --> G
    G --> H[è¾“å‡ºç»™ç”¨æˆ·]
    B --> I[Redisç¼“å­˜]
    B --> J[æ—¥å¿—ç³»ç»Ÿ]
```

---

## 2. æ ¸å¿ƒæ¶æ„

### 2.1 æ•´ä½“æ¶æ„è®¾è®¡

é‡‡ç”¨ **LangChain 1.x æœ€æ–°æ¶æ„æ¨¡å¼** (v1.0+)ï¼š

```python
# æ ¸å¿ƒæ¶æ„ä¼ªä»£ç  (LangChain 1.x æ¨è)
from langchain.agents import create_agent  # âœ… v1.x æ–° API
from langchain_core.tools import tool       # âœ… v1.x ç®€åŒ–å·¥å…·å®šä¹‰
from langchain.chat_models import init_chat_model  # âœ… v1.x ç»Ÿä¸€åˆå§‹åŒ–

# 1. æ¨¡å‹åˆå§‹åŒ–ï¼ˆLangChain 1.x æ¨èï¼‰
llm = init_chat_model(
    "gpt-4",
    temperature=0.7,
    api_key="your-api-key"
)

# 2. å·¥å…·å®šä¹‰ï¼ˆä½¿ç”¨ v1.x ç®€åŒ–è£…é¥°å™¨ï¼‰
@tool
def get_weather(city: str) -> str:
    """è·å–åŸå¸‚å¤©æ°”ä¿¡æ¯"""
    return f"{city} ä»Šå¤©æ™´å¤©ï¼Œæ¸©åº¦ 20-25â„ƒ"

@tool
def search_info(query: str) -> str:
    """æœç´¢ä¿¡æ¯"""
    return f"å…³äº '{query}' çš„æœç´¢ç»“æœ..."

tools = [get_weather, search_info]

# 3. Agent åˆ›å»ºï¼ˆv1.x æ–°æ–¹å¼ï¼‰
agent = create_agent(
    model="gpt-4",
    tools=tools,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·å›ç­”é—®é¢˜ã€‚"
)

# 4. æ‰§è¡Œï¼ˆv1.x æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼ï¼‰
response = agent.invoke({
    "messages": [{"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]
})
```

**å…³é”®å˜åŒ–è¯´æ˜**ï¼š
- âœ… ä½¿ç”¨ `create_agent()` ä»£æ›¿ `create_tool_calling_agent()`
- âœ… ç®€åŒ–çš„ `@tool` è£…é¥°å™¨è‡ªåŠ¨ç”Ÿæˆ JSON Schema
- âœ… æ ‡å‡†åŒ–çš„æ¶ˆæ¯æ ¼å¼ `{"role": "user", "content": "..."}`
- âœ… ç»Ÿä¸€çš„ `init_chat_model()` åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹æä¾›å•†

### 2.2 åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          åº”ç”¨å±‚ (Application)            â”‚
â”‚     - FastAPI Web Service               â”‚
â”‚     - CLI å‘½ä»¤è¡Œæ¥å£                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ä¸šåŠ¡å±‚ (Business Logic)          â”‚
â”‚     - QA Agent (LangChain)               â”‚
â”‚     - å¯¹è¯ç®¡ç† (Conversation)            â”‚
â”‚     - å·¥å…·è·¯ç”± (Tool Router)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å·¥å…·å±‚ (Tools)                  â”‚
â”‚     - å¤©æ°”æŸ¥è¯¢å·¥å…·                        â”‚
â”‚     - æœç´¢å·¥å…·                            â”‚
â”‚     - è‡ªå®šä¹‰å·¥å…·                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      åŸºç¡€è®¾æ–½å±‚ (Infrastructure)         â”‚
â”‚     - Redis ç¼“å­˜                         â”‚
â”‚     - æ—¥å¿—ç³»ç»Ÿ                           â”‚
â”‚     - é…ç½®ç®¡ç†                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. æŠ€æœ¯æ ˆä¸ä¾èµ–

### 3.1 æ ¸å¿ƒæ¡†æ¶

> **âš ï¸ é‡è¦ç‰ˆæœ¬è¦æ±‚**: æœ¬é¡¹ç›®åŸºäº **LangChain v1.x** æ„å»ºï¼Œè¿™æ˜¯ LangChain çš„é‡å¤§ç‰ˆæœ¬æ›´æ–°ï¼Œä¸ v0.x æœ‰ä¸å…¼å®¹çš„å˜æ›´ã€‚è¯¦è§ [LangChain v1.0 å‘å¸ƒè¯´æ˜](https://python.langchain.com/docs/versions/migrating_to_lcel/)

#### LangChain ç”Ÿæ€ (å¿…éœ€)
```txt
# LangChain 1.x æ ¸å¿ƒä¾èµ– (æœ€ä½è¦æ±‚)
langchain>=1.0.0              # LangChain æ ¸å¿ƒåº“ - å¿…é¡»ä½¿ç”¨ v1.0+
langchain-core>=1.0.0         # æ ¸å¿ƒæ¥å£
langchain-openai>=0.2.0       # OpenAI é›†æˆ
langchain-community>=1.0.0    # ç¤¾åŒºå·¥å…·é›†æˆ

# Python ç‰ˆæœ¬è¦æ±‚
# Python >= 3.10 (LangChain 1.x ç¡¬æ€§è¦æ±‚)
# æ¨è Python >= 3.11
```

**âœ¨ LangChain 1.x é‡å¤§å‡çº§**ï¼š
- âœ… ç»Ÿä¸€çš„ `init_chat_model()` æ¨¡å‹åˆå§‹åŒ– API
- âœ… åŸç”Ÿæ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰
- âœ… æ”¹è¿›çš„å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰æœºåˆ¶
- âœ… å®Œå…¨é‡å†™çš„ Agent æ¶æ„ï¼ˆåŸºäº LangGraphï¼‰
- âœ… å¢å¼ºçš„å¼‚æ­¥æ”¯æŒå’Œæµå¼å¤„ç†
- âœ… LCELï¼ˆLangChain Expression Languageï¼‰æ ‡å‡†åŒ–
- âœ… Python 3.10+ ç¡¬æ€§è¦æ±‚ï¼ˆä¸å†æ”¯æŒ 3.9 åŠä»¥ä¸‹ï¼‰

**ğŸ”„ ä» 0.x å‡çº§åˆ° 1.x çš„ä¸»è¦å˜åŒ–**ï¼š
- ä¸å†æ”¯æŒä¼ ç»Ÿçš„ `AgentExecutor`ï¼Œæ”¹ç”¨æ–°çš„ `create_agent()` API
- æ¨¡å‹åˆå§‹åŒ–æ¨èä½¿ç”¨ `init_chat_model()`
- å·¥å…·å®šä¹‰ä½¿ç”¨ `@tool` è£…é¥°å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
- Prompt æ¨¡æ¿ä½¿ç”¨æ–°çš„ `ChatPromptTemplate`

#### AI æ¨¡å‹æä¾›å•†
```txt
openai>=1.12.0                # OpenAI API å®¢æˆ·ç«¯
```

### 3.2 æ•°æ®éªŒè¯ä¸é…ç½®

```txt
# Pydantic 2.x (æ¨è)
pydantic>=2.7.4               # æ•°æ®éªŒè¯
pydantic-settings>=2.3.4      # é…ç½®ç®¡ç†
```

**Pydantic 2.x ä¼˜åŠ¿**ï¼š
- ğŸš€ æ€§èƒ½æå‡ 5-50 å€
- ğŸ” æ›´å¥½çš„é”™è¯¯ä¿¡æ¯
- ğŸ“ åŸç”Ÿ JSON Schema ç”Ÿæˆ
- âœ¨ ä¸¥æ ¼ç±»å‹æ£€æŸ¥

### 3.3 å¤–éƒ¨æœåŠ¡é›†æˆ

```txt
# æœç´¢ä¸åœ°å›¾ API
tavily-python>=0.3.3         # Tavily æœç´¢ API
requests>=2.31.0             # HTTP è¯·æ±‚ï¼ˆé«˜å¾·åœ°å›¾ï¼‰
```

### 3.4 åŸºç¡€è®¾æ–½

```txt
# ç¼“å­˜ä¸å­˜å‚¨
redis>=5.0.1                 # Redis å®¢æˆ·ç«¯

# æ—¥å¿—ä¸ç›‘æ§
loguru>=0.7.2                # ç»“æ„åŒ–æ—¥å¿—

# Web æ¡†æ¶ï¼ˆå¯é€‰ï¼‰
fastapi>=0.104.1             # Web API æ¡†æ¶
uvicorn>=0.24.0              # ASGI æœåŠ¡å™¨
```

### 3.5 å¼€å‘å·¥å…·

```txt
# ç¯å¢ƒç®¡ç†
python-dotenv>=1.0.0         # ç¯å¢ƒå˜é‡ç®¡ç†

# æµ‹è¯•æ¡†æ¶
pytest>=7.4.3                # æµ‹è¯•æ¡†æ¶
pytest-asyncio>=0.21.1       # å¼‚æ­¥æµ‹è¯•
pytest-cov>=4.1.0            # è¦†ç›–ç‡æŠ¥å‘Š

# ä»£ç è´¨é‡
black>=24.1.0                # ä»£ç æ ¼å¼åŒ–
ruff>=0.1.0                  # å¿«é€Ÿ Linter
mypy>=1.8.0                  # ç±»å‹æ£€æŸ¥
```

---

## 4. é¡¹ç›®ç»“æ„

### 4.1 æ ‡å‡†ä¼ä¸šçº§ç›®å½•ç»“æ„

```
multi-task-qa-assistant/
â”œâ”€â”€ .env                          # ç¯å¢ƒå˜é‡é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
â”œâ”€â”€ .env.example                  # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .env.development              # å¼€å‘ç¯å¢ƒé…ç½®
â”œâ”€â”€ .env.test                     # æµ‹è¯•ç¯å¢ƒé…ç½®
â”œâ”€â”€ .gitignore                    # Git å¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ é¡¹ç›®ç»“æ„è¯´æ˜æ–‡æ¡£.md            # æœ¬æ–‡æ¡£
â”œâ”€â”€ CHANGELOG.md                  # å˜æ›´æ—¥å¿—
â”œâ”€â”€ LICENSE                       # å¼€æºåè®®
â”‚
â”œâ”€â”€ requirements/                 # ä¾èµ–ç®¡ç†
â”‚   â”œâ”€â”€ base.txt                 # åŸºç¡€ä¾èµ–
â”‚   â”œâ”€â”€ dev.txt                  # å¼€å‘ä¾èµ–
â”‚   â”œâ”€â”€ prod.txt                 # ç”Ÿäº§ä¾èµ–
â”‚   â””â”€â”€ test.txt                 # æµ‹è¯•ä¾èµ–
â”‚
â”œâ”€â”€ src/                          # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # åº”ç”¨å…¥å£ â­
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                  # Agent æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ qa_agent.py          # é—®ç­” Agent å®ç° â­
â”‚   â”‚   â””â”€â”€ agent_factory.py     # Agent å·¥å‚æ¨¡å¼
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                   # å·¥å…·æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # å·¥å…·åŸºç±»
â”‚   â”‚   â”œâ”€â”€ weather/             # å¤©æ°”å·¥å…·åŒ…
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ amap_weather_tool.py    # é«˜å¾·å¤©æ°”å·¥å…· â­
â”‚   â”‚   â”‚   â””â”€â”€ weather_schemas.py      # å¤©æ°”æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ search/              # æœç´¢å·¥å…·åŒ…
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ tavily_search_tool.py   # Tavily æœç´¢å·¥å…· â­
â”‚   â”‚       â””â”€â”€ search_schemas.py       # æœç´¢æ•°æ®æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                  # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py          # ä¸»é…ç½®ç±» â­
â”‚   â”‚   â”œâ”€â”€ prompts.py           # Prompt æ¨¡æ¿ç®¡ç†
â”‚   â”‚   â””â”€â”€ constants.py         # å¸¸é‡å®šä¹‰
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                    # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py            # æ—¥å¿—ç³»ç»Ÿ â­
â”‚   â”‚   â”œâ”€â”€ cache.py             # ç¼“å­˜ç®¡ç†
â”‚   â”‚   â””â”€â”€ exceptions.py        # è‡ªå®šä¹‰å¼‚å¸¸
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conversation.py      # å¯¹è¯æ¨¡å‹
â”‚   â”‚   â””â”€â”€ message.py           # æ¶ˆæ¯æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                     # API æ¥å£ï¼ˆå¯é€‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/              # è·¯ç”±å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ dependencies.py      # ä¾èµ–æ³¨å…¥
â”‚   â”‚   â””â”€â”€ middleware.py        # ä¸­é—´ä»¶
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ helpers.py           # è¾…åŠ©å‡½æ•°
â”‚       â””â”€â”€ validators.py        # éªŒè¯å™¨
â”‚
â”œâ”€â”€ tests/                       # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py              # pytest é…ç½®
â”‚   â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_tools.py
â”‚   â”‚   â””â”€â”€ test_agents.py
â”‚   â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯•
â”‚   â”‚   â””â”€â”€ test_agent_flow.py
â”‚   â””â”€â”€ e2e/                     # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚       â””â”€â”€ test_conversation.py
â”‚
â”œâ”€â”€ scripts/                     # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ setup_environment.py     # ç¯å¢ƒåˆå§‹åŒ– â­
â”‚   â”œâ”€â”€ deploy.sh                # éƒ¨ç½²è„šæœ¬
â”‚   â””â”€â”€ backup.sh                # å¤‡ä»½è„šæœ¬
â”‚
â”œâ”€â”€ data/                        # æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ AMap_adcode_citycode.xlsx  # é«˜å¾·åŸå¸‚ä»£ç 
â”‚   â””â”€â”€ knowledge_base/          # çŸ¥è¯†åº“æ•°æ®
â”‚
â”œâ”€â”€ logs/                        # æ—¥å¿—ç›®å½•
â”‚   â”œâ”€â”€ app_2025-01-02.log       # åº”ç”¨æ—¥å¿—
â”‚   â”œâ”€â”€ api_2025-01-02.log       # API æ—¥å¿—
â”‚   â””â”€â”€ error_2025-01-02.log     # é”™è¯¯æ—¥å¿—
â”‚
â”œâ”€â”€ docs/                        # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ api/                     # API æ–‡æ¡£
â”‚   â”œâ”€â”€ guides/                  # ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ architecture/            # æ¶æ„æ–‡æ¡£
â”‚
â”œâ”€â”€ deployments/                 # éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ docker/                  # Docker é…ç½®
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ kubernetes/              # K8s é…ç½®
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â””â”€â”€ terraform/               # åŸºç¡€è®¾æ–½ä»£ç 
â”‚
â”œâ”€â”€ .github/                     # GitHub é…ç½®
â”‚   â””â”€â”€ workflows/               # CI/CD å·¥ä½œæµ
â”‚       â”œâ”€â”€ test.yml
â”‚       â””â”€â”€ deploy.yml
â”‚
â””â”€â”€ .venv/                       # Python è™šæ‹Ÿç¯å¢ƒ
```

### 4.2 æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

#### â­ `src/main.py` - åº”ç”¨å…¥å£
```python
"""
ä¼ä¸šçº§åº”ç”¨å…¥å£ç¤ºä¾‹
"""
import asyncio
from langchain.chat_models import init_chat_model
from src.agents.qa_agent import create_qa_agent
from src.core.logger import setup_logger
from src.config.settings import settings

logger = setup_logger(__name__)

async def main():
    """ä¸»åº”ç”¨å…¥å£"""
    logger.info("ğŸš€ å¯åŠ¨å¤šä»»åŠ¡é—®ç­”åŠ©æ‰‹")

    # 1. åˆå§‹åŒ–æ¨¡å‹ï¼ˆLangChain 1.x æ¨èï¼‰
    llm = init_chat_model(
        settings.MODEL_NAME,
        temperature=settings.MODEL_TEMPERATURE,
        api_key=settings.OPENAI_API_KEY
    )

    # 2. åˆ›å»º Agent
    agent = create_qa_agent(llm)

    # 3. è¿è¡Œåº”ç”¨
    while True:
        user_input = input("\nç”¨æˆ·: ")
        if user_input.lower() in ['exit', 'quit']:
            break

        try:
            response = await agent.ainvoke({"input": user_input})
            print(f"\nåŠ©æ‰‹: {response['output']}")
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

#### â­ `src/config/settings.py` - é…ç½®ç®¡ç†
```python
"""
åŸºäº Pydantic Settings çš„é…ç½®ç®¡ç†
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import Literal

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®ç±»"""

    # æ¨¡å‹é…ç½®
    MODEL_NAME: Literal["gpt-4", "gpt-3.5-turbo"] = "gpt-3.5-turbo"
    MODEL_TEMPERATURE: float = 0.7
    MODEL_MAX_TOKENS: int = 2000

    # API å¯†é’¥
    OPENAI_API_KEY: str
    TAVILY_API_KEY: str
    AMAP_API_KEY: str

    # Redis é…ç½®
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    REDIS_DB: int = 0
    REDIS_PASSWORD: str | None = None

    # æ—¥å¿—é…ç½®
    LOG_LEVEL: Literal["DEBUG", "INFO", "WARNING", "ERROR"] = "INFO"
    LOG_DIR: str = "logs"

    # åº”ç”¨é…ç½®
    APP_NAME: str = "Multi-Task QA Assistant"
    APP_VERSION: str = "1.0.0"
    DEBUG: bool = False

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=True
    )

settings = Settings()
```

#### â­ `src/agents/qa_agent.py` - Agent å®ç°
```python
"""
LangChain 1.x Agent å®ç° (v1.0+)
ä½¿ç”¨æœ€æ–°çš„ create_agent() API
"""
from langchain.agents import create_agent  # âœ… v1.x æ–° API
from langchain_core.tools import tool       # âœ… v1.x ç®€åŒ–å·¥å…·å®šä¹‰
from langchain.chat_models import init_chat_model  # âœ… v1.x ç»Ÿä¸€åˆå§‹åŒ–
from src.core.logger import get_logger

logger = get_logger(__name__)

# 1. ä½¿ç”¨ v1.x ç®€åŒ–çš„å·¥å…·å®šä¹‰
@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

    Args:
        city: åŸå¸‚åç§°ï¼Œå¦‚"åŒ—äº¬"ã€"ä¸Šæµ·"

    Returns:
        å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²
    """
    # è°ƒç”¨é«˜å¾·å¤©æ°” API
    return f"{city} ä»Šå¤©æ™´å¤©ï¼Œæ¸©åº¦ 15-25â„ƒï¼Œç©ºæ°”è´¨é‡è‰¯å¥½"

@tool
def search_tavily(query: str) -> str:
    """ä½¿ç”¨ Tavily æœç´¢å¼•æ“æœç´¢ä¿¡æ¯

    Args:
        query: æœç´¢æŸ¥è¯¢

    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    # è°ƒç”¨ Tavily API
    return f"å…³äº '{query}' çš„æœç´¢ç»“æœï¼š..."

def create_qa_agent():
    """åˆ›å»ºé—®ç­” Agent (LangChain 1.x æ–¹å¼)"""

    # 2. å‡†å¤‡å·¥å…·åˆ—è¡¨
    tools = [get_weather, search_tavily]

    # 3. åˆ›å»º Agentï¼ˆv1.x æ–° APIï¼‰
    agent = create_agent(
        model="gpt-4",
        tools=tools,
        system_prompt=(
            "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢å¤©æ°”å’Œæœç´¢ä¿¡æ¯ã€‚"
            "æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚"
        )
    )

    logger.info("âœ… QA Agent åˆ›å»ºæˆåŠŸ (LangChain 1.x)")
    return agent

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    agent = create_qa_agent()

    # v1.x æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼
    response = agent.invoke({
        "messages": [
            {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
        ]
    })

    print(f"å›å¤: {response}")
```

**v1.x vs v0.x å¯¹æ¯”**ï¼š
```python
# âŒ æ—§ç‰ˆ (v0.x) - ä¸æ¨è
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4")
agent = create_tool_calling_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools)
response = executor.invoke({"input": "ç”¨æˆ·é—®é¢˜"})

# âœ… æ–°ç‰ˆ (v1.x) - æ¨è
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4",
    tools=tools,
    system_prompt="ç³»ç»Ÿæç¤º"
)
response = agent.invoke({"messages": [{"role": "user", "content": "ç”¨æˆ·é—®é¢˜"}]})
```

---

## 5. LangChain 1.x æ ¸å¿ƒç‰¹æ€§

### 5.1 ç»Ÿä¸€æ¨¡å‹åˆå§‹åŒ–

```python
# âœ… LangChain 1.x æ¨èæ–¹å¼
from langchain.chat_models import init_chat_model

# è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
model = init_chat_model("gpt-4")

# ç­‰ä»·äºä¼ ç»Ÿæ–¹å¼
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4")
```

**ä¼˜åŠ¿**ï¼š
- ğŸ¯ æ›´ç®€æ´çš„ API
- ğŸ”„ è‡ªåŠ¨åˆ‡æ¢ä¸åŒæ¨¡å‹æä¾›å•†
- ğŸŒ æ”¯æŒ OpenAIã€Anthropicã€Google ç­‰
- ğŸ“ ç»Ÿä¸€çš„æ¥å£

### 5.2 ç»“æ„åŒ–è¾“å‡º

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class WeatherResponse(BaseModel):
    """å¤©æ°”å“åº”æ¨¡å‹"""
    city: str = Field(description="åŸå¸‚åç§°")
    temperature: float = Field(description="æ¸©åº¦ï¼ˆâ„ƒï¼‰")
    condition: str = Field(description="å¤©æ°”çŠ¶å†µ")
    humidity: int = Field(description="æ¹¿åº¦ï¼ˆ%ï¼‰")

# ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
parser = PydanticOutputParser(pydantic_object=WeatherResponse)
structured_llm = llm.with_structured_output(WeatherResponse)

result = structured_llm.invoke("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
# è¿”å› WeatherResponse å¯¹è±¡ï¼Œæ”¯æŒç±»å‹æç¤ºå’ŒéªŒè¯
```

### 5.3 æ”¹è¿›çš„å·¥å…·è°ƒç”¨

```python
from langchain_core.tools import tool

@tool
def search_weather(query: str) -> str:
    """æœç´¢å¤©æ°”ä¿¡æ¯

    Args:
        query: æœç´¢æŸ¥è¯¢ï¼Œå¦‚"åŒ—äº¬å¤©æ°”"

    Returns:
        å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²
    """
    # å·¥å…·å®ç°
    return "åŒ—äº¬ä»Šå¤©æ™´å¤©ï¼Œæ¸©åº¦ 15-25â„ƒ"

# LangChain 1.x è‡ªåŠ¨ç”Ÿæˆå·¥å…·è°ƒç”¨ JSON Schema
print(search_weather.name)        # "search_weather"
print(search_weather.description)  # å·¥å…·æè¿°
print(search_weather.args_schema)  # Pydantic æ¨¡å‹
```

### 5.4 LCEL (LangChain Expression Language)

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# ä½¿ç”¨ LCEL æ„å»ºé“¾
chain = (
    {"input": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# æˆ–ä½¿ç”¨ç®¡é“æ“ä½œç¬¦
chain = prompt | llm | StrOutputParser()

# æ”¯æŒæµå¼è¾“å‡º
async for chunk in chain.astream("ä½ å¥½"):
    print(chunk, end="", flush=True)
```

---

## 6. ä¼ä¸šçº§æœ€ä½³å®è·µ

### 6.1 é…ç½®ç®¡ç†

#### å¤šç¯å¢ƒé…ç½®
```bash
# .env.example
# æ¨¡å‹é…ç½®
MODEL_NAME=gpt-3.5-turbo
MODEL_TEMPERATURE=0.7

# API å¯†é’¥
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
AMAP_API_KEY=your_amap_api_key_here

# Redis é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_DIR=logs
```

#### é…ç½®éªŒè¯
```python
from pydantic import field_validator

class Settings(BaseSettings):
    OPENAI_API_KEY: str

    @field_validator("OPENAI_API_KEY")
    @classmethod
    def validate_api_key(cls, v: str) -> str:
        if not v.startswith("sk-"):
            raise ValueError("æ— æ•ˆçš„ OpenAI API Key")
        return v
```

### 6.2 æ—¥å¿—ä¸ç›‘æ§

#### ç»“æ„åŒ–æ—¥å¿—
```python
from loguru import logger
import sys

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO"
)
logger.add(
    "logs/app_{time:YYYY-MM-DD}.log",
    rotation="1 day",
    retention="30 days",
    level="DEBUG"
)

# ä½¿ç”¨æ—¥å¿—
logger.info("ç”¨æˆ·è¯·æ±‚", extra={"user_id": 123, "query": "å¤©æ°”"})
logger.error("APIè°ƒç”¨å¤±è´¥", extra={"api": "openai", "error": str(e)})
```

#### æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {duration:.2f}s")
            return result
        except Exception as e:
            logger.error(f"{func.__name__} å¤±è´¥: {e}")
            raise
    return wrapper
```

### 6.3 é”™è¯¯å¤„ç†

```python
from src.core.exceptions import (
    ToolExecutionError,
    APIError,
    ValidationError
)

async def safe_tool_call(tool, input_data):
    """å®‰å…¨çš„å·¥å…·è°ƒç”¨"""
    try:
        result = await tool.ainvoke(input_data)
        return result
    except ValidationError as e:
        logger.error(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
        raise
    except APIError as e:
        logger.error(f"API è°ƒç”¨å¤±è´¥: {e}")
        # é‡è¯•é€»è¾‘
        return await retry_tool_call(tool, input_data)
    except Exception as e:
        logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
        raise ToolExecutionError(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
```

### 6.4 ç¼“å­˜ç­–ç•¥

```python
import redis
import json
from typing import Any

class CacheManager:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    async def get(self, key: str) -> Any | None:
        """è·å–ç¼“å­˜"""
        cached = self.redis.get(key)
        if cached:
            return json.loads(cached)
        return None

    async def set(self, key: str, value: Any, ttl: int = 3600):
        """è®¾ç½®ç¼“å­˜"""
        self.redis.setex(
            key,
            ttl,
            json.dumps(value, ensure_ascii=False)
        )

# ä½¿ç”¨ç¤ºä¾‹
cache = CacheManager(redis_client)

cached_result = await cache.get(f"weather:{city}")
if cached_result:
    return cached_result

# è°ƒç”¨ API
result = await get_weather(city)
await cache.set(f"weather:{city}", result, ttl=1800)
```

---

## 7. éƒ¨ç½²ä¸è¿ç»´

### 7.1 Docker å®¹å™¨åŒ–

#### Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements/prod.txt requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶æºä»£ç 
COPY src/ src/
COPY data/ data/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker-compose.yml
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=gpt-3.5-turbo
      - REDIS_HOST=redis
    depends_on:
      - redis
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

### 7.2 Kubernetes éƒ¨ç½²

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qa-assistant
spec:
  replicas: 3
  selector:
    matchLabels:
      app: qa-assistant
  template:
    metadata:
      labels:
        app: qa-assistant
    spec:
      containers:
      - name: app
        image: qa-assistant:latest
        ports:
        - containerPort: 8000
        env:
        - name: MODEL_NAME
          value: "gpt-3.5-turbo"
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: openai
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
---
apiVersion: v1
kind: Service
metadata:
  name: qa-assistant-service
spec:
  selector:
    app: qa-assistant
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

### 7.3 CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install dependencies
      run: |
        pip install -r requirements/test.txt
    - name: Run tests
      run: |
        pytest --cov=src tests/

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to production
      run: |
        # éƒ¨ç½²å‘½ä»¤
        kubectl apply -f deployments/kubernetes/
```

---

## 8. æ€§èƒ½ä¼˜åŒ–

### 8.1 å¼‚æ­¥å¤„ç†

```python
import asyncio
from langchain.chat_models import init_chat_model

async def batch_process(queries: list[str]):
    """æ‰¹é‡å¤„ç†æŸ¥è¯¢"""
    llm = init_chat_model("gpt-3.5-turbo")

    # å¹¶å‘å¤„ç†
    tasks = [llm.ainvoke([HumanMessage(q)]) for q in queries]
    results = await asyncio.gather(*tasks)

    return results

# æ€§èƒ½æå‡ï¼š3-5å€
```

### 8.2 è¿æ¥æ± 

```python
from httpx import AsyncClient, Limits

# åˆ›å»ºè¿æ¥æ± 
client = AsyncClient(
    limits=Limits(max_connections=100, max_keepalive_connections=20),
    timeout=30.0
)

# å¤ç”¨è¿æ¥
async def call_api(url: str):
    async with client.stream('GET', url) as response:
        return await response.text()
```

### 8.3 åŠ¨æ€æ¨¡å‹é€‰æ‹©

> **ğŸ“Œ ç›¸å…³æ–‡ä»¶**:
> - [`æ¨¡å‹åŠ¨æ€é€‰æ‹©ç¤ºä¾‹.py`](./æ¨¡å‹åŠ¨æ€é€‰æ‹©ç¤ºä¾‹.py) - å®Œæ•´çš„åŠ¨æ€æ¨¡å‹é€‰æ‹©ç³»ç»Ÿ
> - [`æ™ºèƒ½é—®ç­”ç³»ç»Ÿ_åŠ¨æ€æ¨¡å‹é›†æˆ.py`](./æ™ºèƒ½é—®ç­”ç³»ç»Ÿ_åŠ¨æ€æ¨¡å‹é›†æˆ.py) - é›†æˆåˆ°é—®ç­”ç³»ç»Ÿçš„å®ç°

#### æ ¸å¿ƒæ¦‚å¿µ

åŠ¨æ€æ¨¡å‹é€‰æ‹©æ˜¯ä¼ä¸šçº§ AI åº”ç”¨çš„å…³é”®ä¼˜åŒ–æŠ€æœ¯ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼Œå®ç°ï¼š

- **æˆæœ¬ä¼˜åŒ–**: ç®€å•ä»»åŠ¡ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹ï¼ˆGPT-3.5ï¼‰
- **æ€§èƒ½ä¼˜åŒ–**: å¤æ‚ä»»åŠ¡ä½¿ç”¨å¼ºå¤§çš„æ¨¡å‹ï¼ˆGPT-4ï¼‰
- **æ™ºèƒ½è·¯ç”±**: è‡ªåŠ¨åˆ†æä»»åŠ¡éœ€æ±‚å¹¶è·¯ç”±

#### æ¶æ„è®¾è®¡

```python
from langchain.chat_models import init_chat_model
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from enum import Enum

class ModelType(str, Enum):
    GPT35_TURBO = "gpt-3.5-turbo"   # å¿«é€Ÿç»æµ
    GPT4_TURBO = "gpt-4-turbo"      # å¹³è¡¡
    GPT4 = "gpt-4"                 # æœ€å¼º

class TaskComplexity(str, Enum):
    SIMPLE = "simple"      # é—®å€™ã€é—²èŠ
    MEDIUM = "medium"      # æŸ¥è¯¢ã€è§£é‡Š
    COMPLEX = "complex"    # åˆ†æã€æ¨ç†

# 1. ä»»åŠ¡åˆ†æå™¨
class TaskAnalyzer:
    def analyze(self, query: str) -> TaskComplexity:
        # åŸºäºè§„åˆ™æˆ– ML æ¨¡å‹åˆ†æä»»åŠ¡
        if "ä½ å¥½" in query:
            return TaskComplexity.SIMPLE
        elif "åˆ†æ" in query:
            return TaskComplexity.COMPLEX
        return TaskComplexity.MEDIUM

# 2. æ¨¡å‹é€‰æ‹©å™¨
class ModelSelector:
    def select(self, complexity: TaskComplexity) -> ModelType:
        routing_rules = {
            TaskComplexity.SIMPLE: ModelType.GPT35_TURBO,
            TaskComplexity.MEDIUM: ModelType.GPT4_TURBO,
            TaskComplexity.COMPLEX: ModelType.GPT4,
        }
        return routing_rules[complexity]

# 3. åŠ¨æ€è·¯ç”±å™¨ï¼ˆä¸­é—´ä»¶æ¨¡å¼ï¼‰
class DynamicModelRouter:
    def __init__(self):
        self.analyzer = TaskAnalyzer()
        self.selector = ModelSelector()
        self.models = {}

    def route(self, query: str):
        # åˆ†æä»»åŠ¡
        complexity = self.analyzer.analyze(query)

        # é€‰æ‹©æ¨¡å‹
        model_type = self.selector.select(complexity)

        # è·å–æˆ–åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰
        if model_type not in self.models:
            self.models[model_type] = init_chat_model(model_type.value)

        return self.models[model_type]
```

#### ä¸­é—´ä»¶é›†æˆ

```python
# ä½¿ç”¨ LangChain 1.x ä¸­é—´ä»¶æ¨¡å¼
router = DynamicModelRouter()

# åˆ›å»ºè·¯ç”±ä¸­é—´ä»¶
@RunnableLambda
def routing_middleware(input_dict: dict) -> dict:
    query = input_dict["query"]
    model = router.route(query)
    input_dict["_model"] = model
    return input_dict

# åˆ›å»ºå¤„ç†é“¾
chain = (
    RunnablePassthrough.assign(query=lambda x: x["query"])
    | routing_middleware          # åŠ¨æ€æ¨¡å‹é€‰æ‹©
    | RunnableLambda(process_with_model)  # ä½¿ç”¨é€‰å®šçš„æ¨¡å‹å¤„ç†
)

# ä½¿ç”¨
result = chain.invoke({"query": "åˆ†æä¸‰ä¸ªAIæ¡†æ¶çš„ä¼˜ç¼ºç‚¹"})
# è‡ªåŠ¨é€‰æ‹© GPT-4 å¤„ç†å¤æ‚ä»»åŠ¡
```

#### æˆæœ¬ä¼˜åŒ–æ•ˆæœ

| ä»»åŠ¡ç±»å‹ | ä¼ ç»Ÿæ–¹å¼ | åŠ¨æ€é€‰æ‹© | èŠ‚çœæˆæœ¬ |
|---------|---------|---------|---------|
| ç®€å•é—®å€™ | GPT-4 ($0.03) | GPT-3.5 ($0.002) | **93%** |
| æŸ¥è¯¢è§£é‡Š | GPT-4 ($0.03) | GPT-4 Turbo ($0.01) | **67%** |
| å¤æ‚åˆ†æ | GPT-4 ($0.03) | GPT-4 ($0.03) | 0% |

**ç»¼åˆèŠ‚çœ**: çº¦ **60-80%** çš„æˆæœ¬ï¼ˆå–å†³äºä»»åŠ¡åˆ†å¸ƒï¼‰

#### é«˜çº§ç‰¹æ€§

##### 1. A/B æµ‹è¯•æ”¯æŒ
```python
class ABTestRouter:
    def assign_group(self, user_id: str) -> str:
        # ä¸ºç”¨æˆ·åˆ†é…æµ‹è¯•ç»„
        group = "A" if hash(user_id) % 2 == 0 else "B"
        return group

    def get_model(self, user_id: str):
        group = self.assign_group(user_id)
        return {
            "A": ModelType.GPT4_TURBO,  # å¯¹ç…§ç»„
            "B": ModelType.GPT4          # å®éªŒç»„
        }[group]
```

##### 2. å†³ç­–æ—¥å¿—
```python
class ModelSelectionLogger:
    def log_decision(self, query: str, analysis: TaskAnalyzer, model: ModelType):
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "complexity": analysis.complexity,
            "model_selected": model.value,
            "estimated_cost": calculate_cost(analysis, model)
        }
        # å†™å…¥æ—¥å¿—æˆ–æ•°æ®åº“ç”¨äºåˆ†æ
        logger.info(f"æ¨¡å‹é€‰æ‹©å†³ç­–: {log_entry}")
```

##### 3. é…ç½®åŒ–è·¯ç”±è§„åˆ™
```python
# model_routing_config.yaml
rules:
  simple:
    model: "gpt-3.5-turbo"
    conditions:
      token_count: {"lt": 500}
      keywords: ["ä½ å¥½", "hello", "hi"]

  medium:
    model: "gpt-4-turbo"
    conditions:
      token_count: {"gte": 500, "lt": 2000}

  complex:
    model: "gpt-4"
    conditions:
      token_count: {"gte": 2000}
      requires_reasoning: true

  cost_optimized:
    model: "gpt-3.5-turbo"
    priority: 1  # æœ€é«˜ä¼˜å…ˆçº§
```

#### ä½¿ç”¨ç¤ºä¾‹

å‚è§ [`æ™ºèƒ½é—®ç­”ç³»ç»Ÿ_åŠ¨æ€æ¨¡å‹é›†æˆ.py`](./æ™ºèƒ½é—®ç­”ç³»ç»Ÿ_åŠ¨æ€æ¨¡å‹é›†æˆ.py) ä¸­çš„å®Œæ•´å®ç°ï¼š

```python
from æ™ºèƒ½é—®ç­”ç³»ç»Ÿ_åŠ¨æ€æ¨¡å‹é›†æˆ import SmartQASystem, AppConfig

# åˆ›å»ºé…ç½®
config = AppConfig(
    enable_dynamic_routing=True,
    cost_optimization_enabled=True,
    performance_mode="balanced"  # "balanced" | "cost" | "performance"
)

# åˆ›å»ºé—®ç­”ç³»ç»Ÿ
qa_system = SmartQASystem(config)

# æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡
await qa_system.ask("ä½ å¥½")  # â†’ GPT-3.5 Turboï¼ˆæœ€ä¾¿å®œï¼‰
await qa_system.ask("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")  # â†’ GPT-3.5 Turbo + å·¥å…·
await qa_system.ask("åˆ†æPythonå’ŒGoçš„ä¼˜ç¼ºç‚¹")  # â†’ GPT-4ï¼ˆæœ€å¼ºï¼‰
```

#### æœ€ä½³å®è·µ

1. **åˆ†æä»»åŠ¡å¤æ‚åº¦**: ä½¿ç”¨è§„åˆ™æˆ– ML æ¨¡å‹å‡†ç¡®åˆ†æä»»åŠ¡
2. **ç¼“å­˜æ¨¡å‹å®ä¾‹**: é¿å…é‡å¤åˆå§‹åŒ–æ¨¡å‹
3. **ç›‘æ§æˆæœ¬**: è®°å½•æ¯æ¬¡æ¨¡å‹é€‰æ‹©çš„å†³ç­–å’Œæˆæœ¬
4. **A/B æµ‹è¯•**: å¯¹æ¯”ä¸åŒè·¯ç”±ç­–ç•¥çš„æ•ˆæœ
5. **é…ç½®åŒ–**: å°†è·¯ç”±è§„åˆ™å¤–éƒ¨åŒ–ï¼Œä¾¿äºè°ƒæ•´

### 8.4 ç¼“å­˜ä¼˜åŒ–

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_city_code(city_name: str) -> str:
    """ç¼“å­˜åŸå¸‚ä»£ç æŸ¥è¯¢"""
    # æŸ¥è¯¢é€»è¾‘
    return city_code
```

---

## 9. å®‰å…¨ä¸åˆè§„

### 9.1 API å¯†é’¥ç®¡ç†

```python
from pydantic import Field, validator
from cryptography.fernet import Fernet

class SecureSettings(BaseSettings):
    OPENAI_API_KEY: str = Field(..., repr=False)  # ä¸åœ¨æ—¥å¿—ä¸­æ˜¾ç¤º

    @validator("OPENAI_API_KEY")
    def decrypt_key(cls, v):
        # è§£å¯†åŠ å¯†çš„å¯†é’¥
        fernet = Fernet(settings.ENCRYPTION_KEY)
        return fernet.decrypt(v.encode()).decode()
```

### 9.2 è¾“å…¥éªŒè¯

```python
from pydantic import BaseModel, constr, validator

class UserInput(BaseModel):
    query: constr(min_length=1, max_length=1000)

    @validator("query")
    def sanitize_input(cls, v):
        # æ¸…ç†æ¶æ„è¾“å…¥
        dangerous_patterns = ["<script>", "javascript:", "data:"]
        for pattern in dangerous_patterns:
            if pattern.lower() in v.lower():
                raise ValueError("æ£€æµ‹åˆ°å±é™©è¾“å…¥")
        return v
```

### 9.3 è®¿é—®æ§åˆ¶

```python
from fastapi import Depends, HTTPException, status

async def verify_api_token(api_token: str = Header(...)):
    """éªŒè¯ API Token"""
    if not verify_token(api_token):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="æ— æ•ˆçš„ API Token"
        )
    return api_token

@app.post("/chat", dependencies=[Depends(verify_api_token)])
async def chat_endpoint(request: ChatRequest):
    """éœ€è¦è®¤è¯çš„èŠå¤©æ¥å£"""
    pass
```

---

## ğŸ“Š é™„å½•

### A. æ€§èƒ½åŸºå‡†

| æ“ä½œ | å“åº”æ—¶é—´ | QPS | å¤‡æ³¨ |
|------|----------|-----|------|
| æ™®é€šå¯¹è¯ | 1.2s | 50 | å•æ¬¡è°ƒç”¨ |
| å·¥å…·è°ƒç”¨ | 2.5s | 20 | åŒ…å«å¤–éƒ¨ API |
| æ‰¹é‡å¤„ç† (10) | 3.8s | 26 | å¹¶å‘å¤„ç† |
| ç¼“å­˜å‘½ä¸­ | 50ms | 2000 | Redis ç¼“å­˜ |

### B. ç›‘æ§æŒ‡æ ‡

- âœ… API è°ƒç”¨æˆåŠŸç‡
- âœ… å¹³å‡å“åº”æ—¶é—´
- âœ… å·¥å…·è°ƒç”¨é¢‘ç‡
- âœ… ç¼“å­˜å‘½ä¸­ç‡
- âœ… é”™è¯¯ç‡ç»Ÿè®¡

### C. æŠ€æœ¯æ”¯æŒ

- ğŸ“š [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- ğŸ“š [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/)
- ğŸ’¬ [GitHub Issues](https://github.com/langchain-ai/langchain/issues)

---

## ğŸ”¢ ç‰ˆæœ¬å…¼å®¹æ€§

### Python ç‰ˆæœ¬è¦æ±‚
```txt
Python >= 3.10  # LangChain 1.x ç¡¬æ€§è¦æ±‚
æ¨è Python >= 3.11  # æ€§èƒ½æ›´å¥½
```

### LangChain ç‰ˆæœ¬è¦æ±‚
```txt
langchain>=1.0.0         # å¿…é¡»ä½¿ç”¨ v1.0+
langchain-core>=1.0.0    # æ ¸å¿ƒåº“
langchain-openai>=0.2.0  # OpenAI é›†æˆ
```

### ä¾èµ–å†²çªå¤„ç†
```bash
# å¦‚æœé¡¹ç›®ä¸­æœ‰æ—§ç‰ˆæœ¬ LangChain
pip uninstall langchain langchain-core
pip install -U 'langchain>=1.0.0'

# æ£€æŸ¥ç‰ˆæœ¬
python -c "import langchain; print(langchain.__version__)"
# åº”è¾“å‡º: 1.0.0 æˆ–æ›´é«˜ç‰ˆæœ¬
```

### ä» v0.x å‡çº§åˆ° v1.0
```python
# âŒ v0.x æ–¹å¼ï¼ˆå·²åºŸå¼ƒï¼‰
from langchain.agents import initialize_agent, AgentType, Tool
from langchain.llms import OpenAI

# âœ… v1.x æ–¹å¼ï¼ˆæ¨èï¼‰
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model

# ä¸»è¦å˜æ›´ï¼š
# 1. AgentExecutor â†’ create_agent()
# 2. OpenAI/ChatOpenAI â†’ init_chat_model()
# 3. Tool() â†’ @tool è£…é¥°å™¨
# 4. æ¶ˆæ¯æ ¼å¼ â†’ æ ‡å‡†åŒ– {"role": "...", "content": "..."}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2025-01-02
**ç»´æŠ¤è€…**: æŠ€æœ¯å›¢é˜Ÿ
**è®¸å¯è¯**: MIT
**LangChain ç‰ˆæœ¬**: >= 1.0.0
**Python ç‰ˆæœ¬**: >= 3.10