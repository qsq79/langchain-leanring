"""
Demo 32: è®°å¿†ç®¡ç† - ä¸Šä¸‹æ–‡æŒä¹…åŒ–

æœ¬æ¼”ç¤ºå±•ç¤ºå¦‚ä½•:
1. å®ç°çŸ­æœŸè®°å¿†ï¼ˆä¼šè¯è®°å¿†ï¼‰
2. å®ç°é•¿æœŸè®°å¿†ï¼ˆæŒä¹…åŒ–å­˜å‚¨ï¼‰
3. è®°å¿†æ£€ç´¢å’Œç›¸å…³æ€§
4. è®°å¿†æ‘˜è¦å’Œå‹ç¼©
5. å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¿æŒ

è¿è¡Œæ–¹å¼:
    python demo_32_memory_management.py

å‰ç½®è¦æ±‚:
    - å·²é…ç½® OPENAI_API_KEY
    - å·²å®‰è£… autogen-agentchat å’Œ autogen-ext
    - ç†è§£åŸºç¡€ Agent ä½¿ç”¨

ç›¸å…³æ–‡æ¡£:
    - https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/memory.html
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# è¿™æ ·å¯ä»¥ç›´æ¥è¿è¡Œè„šæœ¬æ–‡ä»¶ï¼Œè€Œä¸éœ€è¦ä»ç‰¹å®šç›®å½•è¿è¡Œ
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent  # å‘ä¸Š 3 çº§åˆ° autogen-learning/
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


import asyncio
from typing import List, Dict, Any, Optional
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from common.config import get_settings
# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¿®å¤ç¼–ç é—®é¢˜
os.environ['PYTHONIOENCODING'] = 'utf-8'


# ===== è®°å¿†ç³»ç»Ÿç±» =====
class MemoryStore:
    """è®°å¿†å­˜å‚¨åŸºç±»"""
    

    def __init__(self):
        self.memories: List[Dict[str, Any]] = []
    
    def add_memory(self, content: str, metadata: Optional[Dict[str, Any]] = None):
        """æ·»åŠ è®°å¿†"""
        memory = {
            "content": content,
            "timestamp": asyncio.get_event_loop().time(),
            "metadata": metadata or {}
        }
        self.memories.append(memory)
        return memory
    
    def search_memories(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸å…³è®°å¿†"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        query_lower = query.lower()
        keywords = query_lower.split()
        
        scored = []
        for memory in self.memories:
            content_lower = memory["content"].lower()
            score = sum(1 for keyword in keywords if keyword in content_lower)
            if score > 0:
                scored.append((score, memory))
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        scored.sort(key=lambda x: x[0], reverse=True)
        
        return [m[1] for m in scored[:limit]]
    
    def get_recent_memories(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„è®°å¿†"""
        return self.memories[-limit:] if len(self.memories) > limit else self.memories
    
    def summarize_memories(self) -> str:
        """æ‘˜è¦æ‰€æœ‰è®°å¿†"""
        if not self.memories:
            return "æ²¡æœ‰è®°å¿†"
        
        contents = [m["content"] for m in self.memories]
        all_text = " | ".join(contents)
        
        # ç®€å•æ‘˜è¦ï¼šå–å‰ 200 å­—ç¬¦
        if len(all_text) > 200:
            summary = all_text[:200] + "..."
        else:
            summary = all_text
        
        return summary


class ShortTermMemory(MemoryStore):
    """çŸ­æœŸè®°å¿† - ä¼šè¯çº§åˆ«"""
    
    def __init__(self, max_size: int = 20):
        super().__init__()
        self.max_size = max_size
    
    def add_memory(self, content: str, metadata: Optional[Dict[str, Any]] = None):
        """æ·»åŠ è®°å¿†ï¼Œè¶…å‡ºé™åˆ¶æ—¶åˆ é™¤æœ€æ—§çš„"""
        memory = super().add_memory(content, metadata)
        
        # è¶…å‡ºé™åˆ¶æ—¶åˆ é™¤æœ€æ—§çš„
        if len(self.memories) > self.max_size:
            self.memories = self.memories[-self.max_size:]
        
        return memory
    
    def clear(self):
        """æ¸…ç©ºçŸ­æœŸè®°å¿†"""
        self.memories = []


class LongTermMemory(MemoryStore):
    """é•¿æœŸè®°å¿† - æŒä¹…åŒ–çº§åˆ«"""
    
    def __init__(self, max_size: int = 100):
        super().__init__()
        self.max_size = max_size
    
    def add_memory(self, content: str, metadata: Optional[Dict[str, Any]] = None):
        """æ·»åŠ é‡è¦è®°å¿†åˆ°é•¿æœŸå­˜å‚¨"""
        # åªæ·»åŠ å¸¦é‡è¦æ ‡è®°çš„è®°å¿†
        if metadata and metadata.get("important", False):
            memory = super().add_memory(content, metadata)
            
            # è¶…å‡ºé™åˆ¶æ—¶åˆ é™¤æœ€æ—§çš„
            if len(self.memories) > self.max_size:
                self.memories = self.memories[-self.max_size:]
            
            return memory
        return None
    
    def clear(self):
        """æ¸…ç©ºé•¿æœŸè®°å¿†"""
        self.memories = []


# ===== æ¼”ç¤ºå‡½æ•° =====
async def demo_short_term_memory():
    """æ¼”ç¤º 1: çŸ­æœŸè®°å¿†ä½¿ç”¨"""
    print("=" * 80)
    print("æ¼”ç¤º 1: çŸ­æœŸè®°å¿†ï¼ˆä¼šè¯è®°å¿†ï¼‰")
    print("=" * 80 + "\n")

    settings = get_settings()
    model_client = OpenAIChatCompletionClient(
        model=settings.openai_model,
        api_key=settings.openai_api_key
    )

    # åˆ›å»ºçŸ­æœŸè®°å¿†
    short_memory = ShortTermMemory(max_size=10)

    # åˆ›å»ºä½¿ç”¨è®°å¿†çš„ Agent
    agent = AssistantAgent(
        name="memory_agent",
        model_client=model_client,
        description="ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†çš„åŠ©æ‰‹ï¼Œå¯ä»¥è®°ä½å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯ã€‚"
    )

    print("ğŸ’¬ å¤šè½®å¯¹è¯æµ‹è¯•")
    print()

    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    conversation = [
        "æˆ‘çš„åå­—æ˜¯å°æ˜",
        "æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯è“è‰²",
        "æˆ‘ä½åœ¨åŒ—äº¬",
        "æˆ‘çš„å·¥ä½œæ˜¯ä»€ä¹ˆï¼Ÿ"  # åº”è¯¥åŸºäºè®°å¿†å›ç­”ä¸çŸ¥é“
    ]

    for message in conversation:
        # æ·»åŠ åˆ°è®°å¿†
        short_memory.add_memory(message, metadata={"type": "user_input"})
        
        print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = f"å¯¹è¯å†å²:\n" + "\n".join([
            f"- {m['content']}" for m in short_memory.get_recent_memories(5)
        ])
        
        # Agent å¤„ç†
        result = await agent.run(task=message)
        
        last_message = result.messages[-1]
        print(f"ğŸ¤– åŠ©æ‰‹: {last_message.content[:150]}...")
        print()

    print("ğŸ“Š è®°å¿†æ‘˜è¦:")
    print(short_memory.summarize_memories())

    print("\n" + "=" * 80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 80 + "\n")


async def demo_long_term_memory():
    """æ¼”ç¤º 2: é•¿æœŸè®°å¿†å’Œæ£€ç´¢"""
    print("=" * 80)
    print("æ¼”ç¤º 2: é•¿æœŸè®°å¿†å’Œæ£€ç´¢")
    print("=" * 80 + "\n")

    settings = get_settings()
    model_client = OpenAIChatCompletionClient(
        model=settings.openai_model,
        api_key=settings.openai_api_key
    )

    # åˆ›å»ºé•¿æœŸè®°å¿†
    long_memory = LongTermMemory(max_size=20)

    # åˆ›å»ºä½¿ç”¨é•¿æœŸè®°å¿†çš„ Agent
    agent = AssistantAgent(
        name="long_term_agent",
        model_client=model_client,
        description="ä½ æ˜¯ä¸€ä¸ªæœ‰é•¿æœŸè®°å¿†çš„åŠ©æ‰‹ï¼Œå¯ä»¥è®°ä½é‡è¦çš„ç”¨æˆ·ä¿¡æ¯ã€‚"
    )

    # æ·»åŠ ä¸€äº›åˆå§‹è®°å¿†
    long_memory.add_memory(
        "ç”¨æˆ·æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´ç»éªŒ",
        metadata={"important": True, "category": "work"}
    )
    long_memory.add_memory(
        "ç”¨æˆ·æœ€è¿‘åœ¨å­¦ä¹  AutoGen æ¡†æ¶",
        metadata={"important": True, "category": "learning"}
    )
    long_memory.add_memory(
        "ç”¨æˆ·å¯¹ AI åŠ©æ‰‹ç³»ç»Ÿå¾ˆæ„Ÿå…´è¶£",
        metadata={"important": True, "category": "interest"}
    )

    print("ğŸ’¬ è®°å¿†æ£€ç´¢æµ‹è¯•")
    print()
    print("ğŸ“Š å½“å‰é•¿æœŸè®°å¿†:")
    for memory in long_memory.memories:
        print(f"   - {memory['content']}")
    print()

    # æµ‹è¯•æ£€ç´¢
    queries = [
        "ç”¨æˆ·æœ‰ä»€ä¹ˆå·¥ä½œç»éªŒï¼Ÿ",
        "ç”¨æˆ·åœ¨å­¦ä»€ä¹ˆï¼Ÿ",
        "ç”¨æˆ·å¯¹ä»€ä¹ˆæ„Ÿå…´è¶£ï¼Ÿ"
    ]

    for query in queries:
        print(f"ğŸ‘¤ ç”¨æˆ·: {query}")
        
        # æœç´¢ç›¸å…³è®°å¿†
        relevant_memories = long_memory.search_memories(query, limit=3)
        
        if relevant_memories:
            context = "ç›¸å…³è®°å¿†:\n" + "\n".join([
                f"- {m['content']}" for m in relevant_memories
            ])
        else:
            context = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†"
        
        # Agent å¤„ç†
        result = await agent.run(task=f"{query}\n\n{context}")
        
        last_message = result.messages[-1]
        print(f"ğŸ¤– åŠ©æ‰‹: {last_message.content[:150]}...")
        print()

    print("\n" + "=" * 80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 80 + "\n")


async def demo_memory_summary():
    """æ¼”ç¤º 3: è®°å¿†æ‘˜è¦å’Œå‹ç¼©"""
    print("=" * 80)
    print("æ¼”ç¤º 3: è®°å¿†æ‘˜è¦å’Œå‹ç¼©")
    print("=" * 80 + "\n")

    settings = get_settings()
    model_client = OpenAIChatCompletionClient(
        model=settings.openai_model,
        api_key=settings.openai_api_key
    )

    # åˆ›å»ºè®°å¿†
    memory = MemoryStore()

    # æ·»åŠ å¤§é‡è®°å¿†
    long_text = """
    äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œ
    å¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚
    è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚
    æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨ä¸éœ€è¦æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ ã€‚
    æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚
    """
    
    memory.add_memory(long_text, metadata={"category": "definition"})
    memory.add_memory(
        "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶æ¸…æ™°çš„è¯­æ³•å’Œä»£ç å¯è¯»æ€§è€Œé—»åã€‚",
        metadata={"category": "language"}
    )
    memory.add_memory(
        "AutoGen æ˜¯å¾®è½¯å¼€å‘çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºæ„å»º AI åº”ç”¨ã€‚",
        metadata={"category": "framework"}
    )

    # åˆ›å»ºæ‘˜è¦ Agent
    summarizer = AssistantAgent(
        name="summarizer",
        model_client=model_client,
        description="ä½ æ˜¯ä¸€ä¸ªæ‘˜è¦åŠ©æ‰‹ï¼Œæ“…é•¿æ€»ç»“å’Œå‹ç¼©ä¿¡æ¯ã€‚"
    )

    print("ğŸ’¬ è®°å¿†æ‘˜è¦æµ‹è¯•")
    print()

    # è·å–æ‰€æœ‰è®°å¿†
    all_memories = memory.get_recent_memories(limit=10)
    
    # ç”Ÿæˆæ‘˜è¦
    summary_task = f"""è¯·å°†ä»¥ä¸‹è®°å¿†å†…å®¹æ‘˜è¦ä¸ºä¸€ä¸ªç®€æ´çš„æ€»ç»“ï¼š
{chr(10).join([f"{i+1}. {m['content'][:100]}..." for i, m in enumerate(all_memories)])}

è¦æ±‚ï¼š
1. çªå‡ºå…³é”®ä¿¡æ¯
2. æ§åˆ¶åœ¨ 200 å­—ä»¥å†…
3. ä½¿ç”¨æ¸…æ™°çš„åˆ—è¡¨æ ¼å¼"""
    
    print(f"ğŸ‘¤ ä»»åŠ¡: {summary_task[:100]}...")
    print()

    result = await summarizer.run(task=summary_task)
    
    print("ğŸ“Š æ‘˜è¦ç»“æœ:")
    last_message = result.messages[-1]
    print(f"{last_message.content[:300]}...")

    print("\n" + "=" * 80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 80 + "\n")


async def demo_hybrid_memory():
    """æ¼”ç¤º 4: æ··åˆè®°å¿†ç³»ç»Ÿ"""
    print("=" * 80)
    print("æ¼”ç¤º 4: æ··åˆè®°å¿†ç³»ç»Ÿ")
    print("=" * 80 + "\n")

    settings = get_settings()
    model_client = OpenAIChatCompletionClient(
        model=settings.openai_model,
        api_key=settings.openai_api_key
    )

    # åˆ›å»ºæ··åˆè®°å¿†ç³»ç»Ÿ
    short_term = ShortTermMemory(max_size=5)
    long_term = LongTermMemory(max_size=10)

    # åˆ›å»ºä½¿ç”¨æ··åˆè®°å¿†çš„ Agent
    agent = AssistantAgent(
        name="hybrid_memory_agent",
        model_client=model_client,
        description="ä½ æ˜¯ä¸€ä¸ªæœ‰æ··åˆè®°å¿†ç³»ç»Ÿçš„åŠ©æ‰‹ï¼ŒåŒæ—¶ä½¿ç”¨çŸ­æœŸå’Œé•¿æœŸè®°å¿†ã€‚"
    )

    print("ğŸ’¬ æ··åˆè®°å¿†æµ‹è¯•")
    print()

    # ä¼šè¯ 1: æ·»åŠ é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†
    session1 = [
        "æˆ‘å«æåï¼Œæ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶",
        "æˆ‘çš„ä¸“ä¸šæ˜¯æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ ",
        "æˆ‘ä½åœ¨ä¸Šæµ·"
    ]

    for message in session1:
        print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
        
        # åŒæ—¶æ·»åŠ åˆ°ä¸¤ç§è®°å¿†
        short_term.add_memory(message)
        long_term.add_memory(message, metadata={"important": True})
        
        result = await agent.run(task=message)
        last_message = result.messages[-1]
        print(f"ğŸ¤– åŠ©æ‰‹: {last_message.content[:100]}...")
        print()

    print("\nâ”€ æ–°ä¼šè¯å¼€å§‹ â”€\n")

    # ä¼šè¯ 2: ä½¿ç”¨çŸ­æœŸè®°å¿†
    session2 = [
        "æˆ‘æœ€è¿‘åœ¨åšä»€ä¹ˆé¡¹ç›®ï¼Ÿ",  # åº”è¯¥æ£€ç´¢é•¿æœŸè®°å¿†
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    ]

    for message in session2:
        print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
        
        short_term.add_memory(message)
        
        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼‰
        short_term_context = short_term.summarize_memories()
        long_term_context = "\n".join([
            f"- {m['content']}" for m in long_term.get_recent_memories(5)
        ])
        
        full_context = f"è¿‘æœŸå¯¹è¯:\n{short_term_context}\n\né•¿æœŸè®°å¿†:\n{long_term_context}"
        
        result = await agent.run(task=f"{message}\n\n{full_context}")
        last_message = result.messages[-1]
        print(f"ğŸ¤– åŠ©æ‰‹: {last_message.content[:100]}...")
        print()

    print("\n" + "=" * 80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 80 + "\n")


async def demo_memory_efficiency():
    """æ¼”ç¤º 5: è®°å¿†æ•ˆç‡ä¼˜åŒ–"""
    print("=" * 80)
    print("æ¼”ç¤º 5: è®°å¿†æ•ˆç‡ä¼˜åŒ–")
    print("=" * 80 + "\n")

    settings = get_settings()
    model_client = OpenAIChatCompletionClient(
        model=settings.openai_model,
        api_key=settings.openai_api_key
    )

    # åˆ›å»ºé™åˆ¶å¤§å°çš„è®°å¿†
    memory = ShortTermMemory(max_size=3)

    # åˆ›å»ºæ•ˆç‡ Agent
    agent = AssistantAgent(
        name="efficient_agent",
        model_client=model_client,
        description="ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆåŠ©æ‰‹ï¼Œä¸“æ³¨äºæœ€é‡è¦å’Œæœ€æ–°çš„ä¿¡æ¯ã€‚"
    )

    print("ğŸ’¬ è®°å¿†æ•ˆç‡æµ‹è¯•")
    print()

    # å¿«é€Ÿæ·»åŠ å¤šä¸ªè®°å¿†
    for i in range(5):
        memory.add_memory(f"æ¶ˆæ¯ {i+1}")

    print(f"ğŸ“Š è®°å¿†çŠ¶æ€:")
    print(f"   æ€»è®°å¿†æ•°: {len(memory.memories)}")
    print(f"   æœ€è¿‘3æ¡: {[m['content'] for m in memory.get_recent_memories(3)]}")
    print()

    # æµ‹è¯•æ£€ç´¢
    query = "æœ€æ–°çš„æ¶ˆæ¯æ˜¯ä»€ä¹ˆï¼Ÿ"
    print(f"ğŸ‘¤ ç”¨æˆ·: {query}")
    print()

    # åªä¼ é€’æœ€è¿‘çš„è®°å¿†
    recent_memories = memory.get_recent_memories(3)
    context = "æœ€è¿‘çš„å¯¹è¯:\n" + "\n".join([
        f"- {m['content']}" for m in recent_memories
    ])

    result = await agent.run(task=f"{query}\n\n{context}")
    
    last_message = result.messages[-1]
    print(f"ğŸ¤– åŠ©æ‰‹: {last_message.content}")

    print("\n" + "=" * 80)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 80 + "\n")


# ===== ä¸»å‡½æ•° =====
async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                â•‘
â•‘          AutoGen 0.4+ - è®°å¿†ç®¡ç†æ¼”ç¤º               â•‘
â•‘           Memory Management & Context Persistence          â•‘
â•‘                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    print("=" * 80 + "\n")

    try:
        # æ£€æŸ¥ API Key
        settings = get_settings()
        if not settings.openai_api_key:
            print("âŒ é”™è¯¯: æœªé…ç½® OPENAI_API_KEY")
            print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
            return

        # æ¼”ç¤º 1: çŸ­æœŸè®°å¿†
        await demo_short_term_memory()

        # æ¼”ç¤º 2: é•¿æœŸè®°å¿†
        await demo_long_term_memory()

        # æ¼”ç¤º 3: è®°å¿†æ‘˜è¦
        await demo_memory_summary()

        # æ¼”ç¤º 4: æ··åˆè®°å¿†
        await demo_hybrid_memory()

        # æ¼”ç¤º 5: è®°å¿†æ•ˆç‡
        await demo_memory_efficiency()

        print("=" * 80)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 80)
        print("\nå…³é”®è¦ç‚¹:")
        print("  âœ“ çŸ­æœŸè®°å¿†ç”¨äºä¼šè¯çº§åˆ«çš„ä¸´æ—¶å­˜å‚¨")
        print("  âœ“ é•¿æœŸè®°å¿†ç”¨äºæŒä¹…åŒ–å­˜å‚¨é‡è¦ä¿¡æ¯")
        print("  âœ“ å¯ä»¥å®ç°è®°å¿†æ£€ç´¢å’Œç›¸å…³æ€§åŒ¹é…")
        print("  âœ“ è®°å¿†æ‘˜è¦å’Œå‹ç¼©å¯ä»¥å‡å°‘ token ä½¿ç”¨")
        print("  âœ“ æ··åˆè®°å¿†ç³»ç»Ÿç»“åˆçŸ­æœŸå’Œé•¿æœŸå­˜å‚¨")
        print()
        print("ä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹ demo_33_human_interaction.py å­¦ä¹ äººå·¥äº¤äº’")
        print("  2. æŸ¥çœ‹ demo_34_image_messages.py å­¦ä¹ å¤šæ¨¡æ€")
        print("  3. æŸ¥çœ‹ 03-extensions/ å­¦ä¹ æ‰©å±•åŠŸèƒ½")
        print("=" * 80 + "\n")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())