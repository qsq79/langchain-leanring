# LangChain Callbacks ç»„ä»¶å­¦ä¹ æŒ‡å—

Callbacksæ˜¯LangChainæ¡†æ¶ä¸­ç”¨äºç›‘æ§ã€è°ƒè¯•å’Œæ‰©å±•ç»„ä»¶è¡Œä¸ºçš„æ ¸å¿ƒåŠŸèƒ½ã€‚æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»Callbacksç»„ä»¶çš„æ ¸å¿ƒæ¦‚å¿µã€ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

## ğŸ“‹ æ ¸å¿ƒçŸ¥è¯†ç‚¹

### 1. CallbacksåŸºç¡€æ¦‚å¿µ

#### 1.1 ä»€ä¹ˆæ˜¯Callback
- **å®šä¹‰**ï¼šCallbackæ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨è°ƒç”¨çš„å‡½æ•°æˆ–æ–¹æ³•
- **ä½œç”¨**ï¼šç›‘æ§æ‰§è¡Œè¿‡ç¨‹ã€æ”¶é›†æ•°æ®ã€æ‰©å±•åŠŸèƒ½
- **ç‰¹ç‚¹**ï¼šäº‹ä»¶é©±åŠ¨ã€å¯æ’æ‹”ã€å¼‚æ­¥æ”¯æŒ

#### 1.2 Callbackçš„ç”Ÿå‘½å‘¨æœŸ
- **å¼€å§‹é˜¶æ®µ**ï¼šç»„ä»¶åˆå§‹åŒ–ã€å‡†å¤‡æ‰§è¡Œ
- **æ‰§è¡Œé˜¶æ®µ**ï¼šå¤„ç†è¿‡ç¨‹ä¸­çš„å„ç§äº‹ä»¶
- **ç»“æŸé˜¶æ®µ**ï¼šå®Œæˆæ¸…ç†ã€ç»“æœå¤„ç†
- **é”™è¯¯é˜¶æ®µ**ï¼šå¼‚å¸¸å¤„ç†ã€é”™è¯¯æ¢å¤

### 2. Callbackç±»å‹

#### 2.1 åŸºç¡€Callbacks
- **StreamingStdOutCallbackHandler**ï¼šæµå¼è¾“å‡ºåˆ°æ§åˆ¶å°
- **FileCallbackHandler**ï¼šå°†è¾“å‡ºå†™å…¥æ–‡ä»¶
- **LoggingCallbackHandler**ï¼šè®°å½•æ‰§è¡Œæ—¥å¿—
- **MetricsCallbackHandler**ï¼šæ”¶é›†æ€§èƒ½æŒ‡æ ‡

#### 2.2 é«˜çº§Callbacks
- **AsyncCallbackHandler**ï¼šå¼‚æ­¥å›è°ƒå¤„ç†
- **DatabaseCallbackHandler**ï¼šæ•°æ®åº“è®°å½•
- **MonitoringCallbackHandler**ï¼šå®æ—¶ç›‘æ§
- **SecurityCallbackHandler**ï¼šå®‰å…¨æ£€æŸ¥

#### 2.3 è‡ªå®šä¹‰Callbacks
- **ä¸šåŠ¡é€»è¾‘Callback**ï¼šå®ç°ç‰¹å®šä¸šåŠ¡éœ€æ±‚
- **é›†æˆCallback**ï¼šä¸å¤–éƒ¨ç³»ç»Ÿé›†æˆ
- **åˆ†æCallback**ï¼šæ•°æ®åˆ†æå’ŒæŠ¥å‘Š
- **é€šçŸ¥Callback**ï¼šäº‹ä»¶é€šçŸ¥å’Œå‘Šè­¦

### 3. Callbackäº‹ä»¶

#### 3.1 LLMäº‹ä»¶
- **on_llm_start**ï¼šLLMå¼€å§‹ç”Ÿæˆ
- **on_llm_new_token**ï¼šç”Ÿæˆæ–°token
- **on_llm_end**ï¼šLLMç”Ÿæˆå®Œæˆ
- **on_llm_error**ï¼šLLMç”Ÿæˆé”™è¯¯

#### 3.2 Chainäº‹ä»¶
- **on_chain_start**ï¼šChainå¼€å§‹æ‰§è¡Œ
- **on_chain_end**ï¼šChainæ‰§è¡Œå®Œæˆ
- **on_chain_error**ï¼šChainæ‰§è¡Œé”™è¯¯
- **on_chain_stream**ï¼šChainæµå¼è¾“å‡º

#### 3.3 Agentäº‹ä»¶
- **on_agent_action**ï¼šAgentæ‰§è¡ŒåŠ¨ä½œ
- **on_agent_finish**ï¼šAgentå®Œæˆä»»åŠ¡
- **on_agent_error**ï¼šAgentæ‰§è¡Œé”™è¯¯

#### 3.4 Tooläº‹ä»¶
- **on_tool_start**ï¼šå·¥å…·å¼€å§‹æ‰§è¡Œ
- **on_tool_end**ï¼šå·¥å…·æ‰§è¡Œå®Œæˆ
- **on_tool_error**ï¼šå·¥å…·æ‰§è¡Œé”™è¯¯

### 4. Callback Handler

#### 4.1 BaseCallbackHandler
- **å®šä¹‰**ï¼šæ‰€æœ‰Callback Handlerçš„åŸºç±»
- **æ–¹æ³•**ï¼šå®šä¹‰å„ç§äº‹ä»¶å¤„ç†æ–¹æ³•
- **æ‰©å±•**ï¼šé€šè¿‡ç»§æ‰¿å®ç°è‡ªå®šä¹‰Handler

#### 4.2 CallbackManager
- **åŠŸèƒ½**ï¼šç®¡ç†å¤šä¸ªCallback Handler
- **åè°ƒ**ï¼šåè°ƒHandlerä¹‹é—´çš„æ‰§è¡Œ
- **è¿‡æ»¤**ï¼šæ”¯æŒäº‹ä»¶è¿‡æ»¤å’Œè·¯ç”±

## ğŸ¯ å¸¸è§é¢è¯•é¢˜

### åŸºç¡€æ¦‚å¿µé¢˜

**Q1: LangChainä¸­çš„Callbacksè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ**

**A1:**
- **ç›‘æ§éœ€æ±‚**ï¼šæä¾›å¯¹ç»„ä»¶æ‰§è¡Œè¿‡ç¨‹çš„å…¨é¢ç›‘æ§èƒ½åŠ›
- **è°ƒè¯•æ”¯æŒ**ï¼šå¸®åŠ©å¼€å‘è€…è°ƒè¯•å’Œç†è§£æ‰§è¡Œæµç¨‹
- **æ‰©å±•æ€§**ï¼šå…è®¸åœ¨ä¸ä¿®æ”¹æ ¸å¿ƒä»£ç çš„æƒ…å†µä¸‹æ‰©å±•åŠŸèƒ½
- **æ•°æ®æ”¶é›†**ï¼šæ”¶é›†æ‰§è¡Œæ•°æ®ç”¨äºåˆ†æå’Œä¼˜åŒ–
- **å®æ—¶åé¦ˆ**ï¼šæä¾›å®æ—¶çš„æ‰§è¡ŒçŠ¶æ€å’Œç»“æœåé¦ˆ
- **é›†æˆèƒ½åŠ›**ï¼šä¸å¤–éƒ¨ç³»ç»Ÿï¼ˆæ—¥å¿—ã€ç›‘æ§ã€æ•°æ®åº“ï¼‰é›†æˆ

**Q2: Callback Handlerå’ŒCallback Manageræœ‰ä»€ä¹ˆåŒºåˆ«å’Œè”ç³»ï¼Ÿ**

**A2:**
- **Callback Handler**ï¼š
  - ä¸“æ³¨äºç‰¹å®šçš„äº‹ä»¶å¤„ç†é€»è¾‘
  - å®ç°å…·ä½“çš„ä¸šåŠ¡åŠŸèƒ½ï¼ˆæ—¥å¿—ã€ç›‘æ§ã€å®‰å…¨æ£€æŸ¥ç­‰ï¼‰
  - é€šå¸¸å¤„ç†ä¸€ç§æˆ–å‡ ç§ç›¸å…³çš„äº‹ä»¶ç±»å‹

- **Callback Manager**ï¼š
  - ç®¡ç†å’Œåè°ƒå¤šä¸ªCallback Handler
  - è´Ÿè´£äº‹ä»¶çš„åˆ†å‘å’Œæ‰§è¡Œé¡ºåºæ§åˆ¶
  - æä¾›Handlerçš„æ³¨å†Œã€ç§»é™¤ã€è¿‡æ»¤ç­‰ç®¡ç†åŠŸèƒ½

- **è”ç³»**ï¼š
  - Manageré€šè¿‡Handleræ¥å®ç°å…·ä½“åŠŸèƒ½
  - Handlerä¾èµ–Manageræ¥æ¥æ”¶å’Œå¤„ç†äº‹ä»¶
  - ä¸¤è€…é…åˆå®ç°å®Œæ•´çš„Callbackç³»ç»Ÿ

### æŠ€æœ¯å®ç°é¢˜

**Q3: å¦‚ä½•å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„Callback Handlerï¼Ÿ**

**A3:**
```python
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult
from typing import Any, Dict, List, Optional
import time
import json

class CustomMetricsCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†Callback Handler"""
    
    def __init__(self, log_file: str = "metrics.json"):
        super().__init__()
        self.log_file = log_file
        self.metrics = {
            "llm_calls": [],
            "chain_executions": [],
            "tool_usages": []
        }
        self.start_times = {}
    
    def on_llm_start(
        self, 
        serialized: Dict[str, Any], 
        prompts: List[str], 
        **kwargs: Any
    ) -> None:
        """LLMå¼€å§‹æ—¶çš„å¤„ç†"""
        call_id = id(prompts[0])  # ä½¿ç”¨promptçš„idä½œä¸ºè°ƒç”¨æ ‡è¯†
        self.start_times[call_id] = time.time()
        
        metric = {
            "event": "llm_start",
            "timestamp": self.start_times[call_id],
            "model": serialized.get("name", "unknown"),
            "prompt_length": len(prompts[0]) if prompts else 0
        }
        self.metrics["llm_calls"].append(metric)
    
    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """LLMç»“æŸæ—¶çš„å¤„ç†"""
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        prompt = response.generations[0][0].text if response.generations else ""
        call_id = id(prompt)
        
        if call_id in self.start_times:
            duration = time.time() - self.start_times[call_id]
            del self.start_times[call_id]
        else:
            duration = 0
        
        metric = {
            "event": "llm_end",
            "timestamp": time.time(),
            "duration": duration,
            "token_count": response.llm_output.get("token_usage", {}).get("total_tokens", 0),
            "output_length": len(prompt)
        }
        self.metrics["llm_calls"].append(metric)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_metrics()
    
    def on_chain_start(
        self, 
        serialized: Dict[str, Any], 
        inputs: Dict[str, Any], 
        **kwargs: Any
    ) -> None:
        """Chainå¼€å§‹æ—¶çš„å¤„ç†"""
        execution_id = id(inputs)
        self.start_times[execution_id] = time.time()
        
        metric = {
            "event": "chain_start",
            "timestamp": self.start_times[execution_id],
            "chain_type": serialized.get("name", "unknown"),
            "input_keys": list(inputs.keys())
        }
        self.metrics["chain_executions"].append(metric)
    
    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:
        """Chainç»“æŸæ—¶çš„å¤„ç†"""
        execution_id = id(outputs)
        
        if execution_id in self.start_times:
            duration = time.time() - self.start_times[execution_id]
            del self.start_times[execution_id]
        else:
            duration = 0
        
        metric = {
            "event": "chain_end",
            "timestamp": time.time(),
            "duration": duration,
            "output_keys": list(outputs.keys())
        }
        self.metrics["chain_executions"].append(metric)
        
        self._save_metrics()
    
    def on_tool_start(
        self, 
        serialized: Dict[str, Any], 
        input_str: str, 
        **kwargs: Any
    ) -> None:
        """å·¥å…·å¼€å§‹æ—¶çš„å¤„ç†"""
        tool_id = id(input_str)
        self.start_times[tool_id] = time.time()
        
        metric = {
            "event": "tool_start",
            "timestamp": self.start_times[tool_id],
            "tool_name": serialized.get("name", "unknown"),
            "input_length": len(input_str)
        }
        self.metrics["tool_usages"].append(metric)
    
    def on_tool_end(self, output: str, **kwargs: Any) -> None:
        """å·¥å…·ç»“æŸæ—¶çš„å¤„ç†"""
        tool_id = id(output)
        
        if tool_id in self.start_times:
            duration = time.time() - self.start_times[tool_id]
            del self.start_times[tool_id]
        else:
            duration = 0
        
        metric = {
            "event": "tool_end",
            "timestamp": time.time(),
            "duration": duration,
            "output_length": len(output)
        }
        self.metrics["tool_usages"].append(metric)
        
        self._save_metrics()
    
    def _save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.metrics, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"ä¿å­˜æŒ‡æ ‡å¤±è´¥: {e}")
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        llm_calls = self.metrics["llm_calls"]
        chain_executions = self.metrics["chain_executions"]
        tool_usages = self.metrics["tool_usages"]
        
        return {
            "llm_total_calls": len([c for c in llm_calls if c["event"] == "llm_start"]),
            "avg_llm_duration": self._calculate_average_duration(llm_calls, "llm_end"),
            "chain_total_executions": len([e for e in chain_executions if e["event"] == "chain_start"]),
            "avg_chain_duration": self._calculate_average_duration(chain_executions, "chain_end"),
            "tool_total_usages": len([t for t in tool_usages if t["event"] == "tool_start"]),
            "avg_tool_duration": self._calculate_average_duration(tool_usages, "tool_end")
        }
    
    def _calculate_average_duration(self, events: List[Dict], end_event: str) -> float:
        """è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´"""
        end_events = [e for e in events if e["event"] == end_event]
        if not end_events:
            return 0.0
        
        total_duration = sum(e.get("duration", 0) for e in end_events)
        return total_duration / len(end_events)
```

**Q4: å¦‚ä½•å®ç°ä¸€ä¸ªæ”¯æŒå¼‚æ­¥æ“ä½œçš„Callback Handlerï¼Ÿ**

**A4:**
```python
from langchain_core.callbacks import AsyncCallbackHandler
from langchain_core.outputs import LLMResult
from typing import Any, Dict, List, Optional
import asyncio
import aiofiles
import json

class AsyncFileCallbackHandler(AsyncCallbackHandler):
    """å¼‚æ­¥æ–‡ä»¶å†™å…¥Callback Handler"""
    
    def __init__(self, file_path: str = "async_events.json"):
        super().__init__()
        self.file_path = file_path
        self.events = []
        self._lock = asyncio.Lock()
    
    async def on_llm_start(
        self, 
        serialized: Dict[str, Any], 
        prompts: List[str], 
        **kwargs: Any
    ) -> None:
        """å¼‚æ­¥å¤„ç†LLMå¼€å§‹äº‹ä»¶"""
        event = {
            "event": "llm_start",
            "timestamp": asyncio.get_event_loop().time(),
            "model": serialized.get("name", "unknown"),
            "prompt_count": len(prompts),
            "total_prompt_length": sum(len(p) for p in prompts)
        }
        
        async with self._lock:
            self.events.append(event)
            await self._save_events()
    
    async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """å¼‚æ­¥å¤„ç†æ–°tokenäº‹ä»¶"""
        event = {
            "event": "llm_new_token",
            "timestamp": asyncio.get_event_loop().time(),
            "token": token,
            "token_length": len(token)
        }
        
        async with self._lock:
            self.events.append(event)
            # ç´¯ç§¯åˆ°ä¸€å®šæ•°é‡å†ä¿å­˜ï¼Œé¿å…é¢‘ç¹IO
            if len(self.events) % 10 == 0:
                await self._save_events()
    
    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """å¼‚æ­¥å¤„ç†LLMç»“æŸäº‹ä»¶"""
        event = {
            "event": "llm_end",
            "timestamp": asyncio.get_event_loop().time(),
            "generation_count": len(response.generations),
            "token_usage": response.llm_output.get("token_usage", {})
        }
        
        async with self._lock:
            self.events.append(event)
            await self._save_events()
    
    async def on_chain_error(
        self, 
        error: Exception, 
        **kwargs: Any
    ) -> None:
        """å¼‚æ­¥å¤„ç†Chainé”™è¯¯äº‹ä»¶"""
        event = {
            "event": "chain_error",
            "timestamp": asyncio.get_event_loop().time(),
            "error_type": type(error).__name__,
            "error_message": str(error)
        }
        
        async with self._lock:
            self.events.append(event)
            await self._save_events()
    
    async def _save_events(self):
        """å¼‚æ­¥ä¿å­˜äº‹ä»¶åˆ°æ–‡ä»¶"""
        try:
            async with aiofiles.open(self.file_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(self.events, indent=2, ensure_ascii=False))
        except Exception as e:
            print(f"å¼‚æ­¥ä¿å­˜äº‹ä»¶å¤±è´¥: {e}")
    
    async def get_events(self) -> List[Dict[str, Any]]:
        """å¼‚æ­¥è·å–æ‰€æœ‰äº‹ä»¶"""
        async with self._lock:
            return self.events.copy()
    
    async def clear_events(self) -> None:
        """å¼‚æ­¥æ¸…ç©ºäº‹ä»¶"""
        async with self._lock:
            self.events.clear()
            await self._save_events()
```

### æ¶æ„è®¾è®¡é¢˜

**Q5: LangChainçš„Callbacksç»„ä»¶é‡‡ç”¨äº†ä»€ä¹ˆè®¾è®¡æ¨¡å¼ï¼Ÿ**

**A5:**
- **è§‚å¯Ÿè€…æ¨¡å¼**ï¼šCallback Handlerè§‚å¯Ÿå¹¶å“åº”ç»„ä»¶äº‹ä»¶
- **ç­–ç•¥æ¨¡å¼**ï¼šä¸åŒHandlerå®ç°ä¸åŒçš„äº‹ä»¶å¤„ç†ç­–ç•¥
- **è´£ä»»é“¾æ¨¡å¼**ï¼šå¤šä¸ªHandlerå½¢æˆå¤„ç†é“¾
- **æ¨¡æ¿æ–¹æ³•æ¨¡å¼**ï¼šBaseCallbackHandlerå®šä¹‰äº‹ä»¶å¤„ç†æ¡†æ¶
- **è£…é¥°å™¨æ¨¡å¼**ï¼šCallbackä¸ºæ ¸å¿ƒç»„ä»¶æ·»åŠ ç›‘æ§åŠŸèƒ½
- **å·¥å‚æ¨¡å¼**ï¼šé€šè¿‡å·¥å‚æ–¹æ³•åˆ›å»ºç‰¹å®šç±»å‹çš„Handler

## ğŸ—ï¸ è®¾è®¡æ€è·¯å’Œè®¾è®¡æ¨¡å¼

### 1. äº‹ä»¶é©±åŠ¨æ¶æ„

#### 1.1 äº‹ä»¶å‘å¸ƒè®¢é˜…
```python
class EventBus:
    """äº‹ä»¶æ€»çº¿"""
    
    def __init__(self):
        self.handlers = {}
        self.global_handlers = []
    
    def subscribe(self, event_type: str, handler):
        """è®¢é˜…ç‰¹å®šäº‹ä»¶ç±»å‹"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)
    
    def subscribe_all(self, handler):
        """è®¢é˜…æ‰€æœ‰äº‹ä»¶"""
        self.global_handlers.append(handler)
    
    async def publish(self, event_type: str, data: Any):
        """å‘å¸ƒäº‹ä»¶"""
        # é€šçŸ¥å…¨å±€è®¢é˜…è€…
        for handler in self.global_handlers:
            try:
                await self._notify_handler(handler, event_type, data)
            except Exception as e:
                print(f"Handleré€šçŸ¥å¤±è´¥: {e}")
        
        # é€šçŸ¥ç‰¹å®šäº‹ä»¶è®¢é˜…è€…
        if event_type in self.handlers:
            for handler in self.handlers[event_type]:
                try:
                    await self._notify_handler(handler, event_type, data)
                except Exception as e:
                    print(f"Handleré€šçŸ¥å¤±è´¥: {e}")
    
    async def _notify_handler(self, handler, event_type: str, data: Any):
        """é€šçŸ¥å•ä¸ªHandler"""
        method_name = f"on_{event_type}"
        if hasattr(handler, method_name):
            method = getattr(handler, method_name)
            if asyncio.iscoroutinefunction(method):
                await method(data)
            else:
                method(data)
```

#### 1.2 äº‹ä»¶è¿‡æ»¤å’Œè·¯ç”±
```python
class CallbackRouter:
    """Callbackè·¯ç”±å™¨"""
    
    def __init__(self):
        self.routes = []
        self.default_handler = None
    
    def add_route(self, condition, handler):
        """æ·»åŠ è·¯ç”±è§„åˆ™"""
        self.routes.append((condition, handler))
    
    def set_default(self, handler):
        """è®¾ç½®é»˜è®¤Handler"""
        self.default_handler = handler
    
    async def route(self, event_type: str, data: Any):
        """è·¯ç”±äº‹ä»¶åˆ°åˆé€‚çš„Handler"""
        for condition, handler in self.routes:
            if condition(event_type, data):
                await self._execute_handler(handler, event_type, data)
                return
        
        if self.default_handler:
            await self._execute_handler(self.default_handler, event_type, data)
    
    async def _execute_handler(self, handler, event_type: str, data: Any):
        """æ‰§è¡ŒHandler"""
        method_name = f"on_{event_type}"
        if hasattr(handler, method_name):
            method = getattr(handler, method_name)
            if asyncio.iscoroutinefunction(method):
                await method(data)
            else:
                method(data)
```

### 2. å¼‚æ­¥å¤„ç†æ¶æ„

#### 2.1 å¹¶å‘å®‰å…¨çš„Callback
```python
import asyncio
from threading import Lock

class ThreadSafeCallbackHandler(BaseCallbackHandler):
    """çº¿ç¨‹å®‰å…¨çš„Callback Handler"""
    
    def __init__(self):
        super().__init__()
        self._lock = Lock()
        self._events = []
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """çº¿ç¨‹å®‰å…¨çš„äº‹ä»¶å¤„ç†"""
        with self._lock:
            event = self._create_event("llm_start", serialized, prompts)
            self._events.append(event)
    
    def get_events(self) -> List[Dict]:
        """çº¿ç¨‹å®‰å…¨çš„äº‹ä»¶è·å–"""
        with self._lock:
            return self._events.copy()
    
    def clear_events(self):
        """çº¿ç¨‹å®‰å…¨çš„äº‹ä»¶æ¸…ç†"""
        with self._lock:
            self._events.clear()

class AsyncSafeCallbackHandler(AsyncCallbackHandler):
    """å¼‚æ­¥å®‰å…¨çš„Callback Handler"""
    
    def __init__(self):
        super().__init__()
        self._lock = asyncio.Lock()
        self._events = []
    
    async def on_llm_start(self, serialized, prompts, **kwargs):
        """å¼‚æ­¥å®‰å…¨çš„äº‹ä»¶å¤„ç†"""
        async with self._lock:
            event = await self._create_event("llm_start", serialized, prompts)
            self._events.append(event)
    
    async def get_events(self) -> List[Dict]:
        """å¼‚æ­¥å®‰å…¨çš„äº‹ä»¶è·å–"""
        async with self._lock:
            return self._events.copy()
```

### 3. æ€§èƒ½ä¼˜åŒ–è®¾è®¡

#### 3.1 æ‰¹é‡å¤„ç†
```python
class BatchCallbackHandler(BaseCallbackHandler):
    """æ‰¹é‡å¤„ç†Callback Handler"""
    
    def __init__(self, batch_size: int = 100, flush_interval: float = 5.0):
        super().__init__()
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self._batch = []
        self._last_flush = time.time()
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """æ‰¹é‡æ”¶é›†äº‹ä»¶"""
        event = self._create_event("llm_start", serialized, prompts)
        self._add_to_batch(event)
    
    def on_llm_end(self, response, **kwargs):
        """æ‰¹é‡æ”¶é›†äº‹ä»¶"""
        event = self._create_event("llm_end", response)
        self._add_to_batch(event)
    
    def _add_to_batch(self, event: Dict):
        """æ·»åŠ äº‹ä»¶åˆ°æ‰¹æ¬¡"""
        self._batch.append(event)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        current_time = time.time()
        if (len(self._batch) >= self.batch_size or 
            current_time - self._last_flush >= self.flush_interval):
            self._flush_batch()
            self._last_flush = current_time
    
    def _flush_batch(self):
        """åˆ·æ–°æ‰¹æ¬¡åˆ°å­˜å‚¨"""
        if not self._batch:
            return
        
        try:
            self._save_batch(self._batch)
            self._batch.clear()
        except Exception as e:
            print(f"æ‰¹æ¬¡åˆ·æ–°å¤±è´¥: {e}")
    
    def _save_batch(self, batch: List[Dict]):
        """ä¿å­˜æ‰¹æ¬¡æ•°æ®"""
        # å®ç°å…·ä½“çš„ä¿å­˜é€»è¾‘
        pass
```

#### 3.2 å†…å­˜ä¼˜åŒ–
```python
class MemoryOptimizedCallbackHandler(BaseCallbackHandler):
    """å†…å­˜ä¼˜åŒ–çš„Callback Handler"""
    
    def __init__(self, max_memory_mb: int = 100):
        super().__init__()
        self.max_memory_mb = max_memory_mb
        self._memory_usage = 0
        self._events = []
        self._event_count = 0
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """å†…å­˜ç›‘æ§çš„äº‹ä»¶å¤„ç†"""
        event = self._create_event("llm_start", serialized, prompts)
        self._add_event_with_memory_check(event)
    
    def _add_event_with_memory_check(self, event: Dict):
        """æ·»åŠ äº‹ä»¶å¹¶æ£€æŸ¥å†…å­˜ä½¿ç”¨"""
        event_size = self._estimate_event_size(event)
        
        # æ£€æŸ¥å†…å­˜é™åˆ¶
        while self._memory_usage + event_size > self.max_memory_mb * 1024 * 1024:
            if not self._events:
                break
            
            # ç§»é™¤æœ€æ—§çš„äº‹ä»¶
            old_event = self._events.pop(0)
            self._memory_usage -= self._estimate_event_size(old_event)
        
        self._events.append(event)
        self._memory_usage += event_size
        self._event_count += 1
    
    def _estimate_event_size(self, event: Dict) -> int:
        """ä¼°ç®—äº‹ä»¶å¤§å°"""
        import sys
        return sys.getsizeof(event)
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡"""
        return {
            "total_events": self._event_count,
            "memory_usage_mb": self._memory_usage / (1024 * 1024),
            "max_memory_mb": self.max_memory_mb,
            "memory_usage_percent": (self._memory_usage / (self.max_memory_mb * 1024 * 1024)) * 100
        }
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. Callbackè®¾è®¡åŸåˆ™

1. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªHandlerä¸“æ³¨äºç‰¹å®šçš„åŠŸèƒ½
2. **å¼‚å¸¸å®‰å…¨**ï¼šHandlerå¼‚å¸¸ä¸åº”å½±å“ä¸»æµç¨‹
3. **æ€§èƒ½è€ƒè™‘**ï¼šé¿å…é˜»å¡ä¸»æ‰§è¡Œæµç¨‹
4. **å¹‚ç­‰æ€§**ï¼šé‡å¤å¤„ç†ç›¸åŒäº‹ä»¶åº”äº§ç”Ÿç›¸åŒç»“æœ
5. **èµ„æºç®¡ç†**ï¼šåˆç†ç®¡ç†å†…å­˜ã€æ–‡ä»¶å¥æŸ„ç­‰èµ„æº

### 2. é”™è¯¯å¤„ç†å’Œæ¢å¤

```python
class ResilientCallbackHandler(BaseCallbackHandler):
    """å…·æœ‰å®¹é”™èƒ½åŠ›çš„Callback Handler"""
    
    def __init__(self, max_retries: int = 3, fallback_handler=None):
        super().__init__()
        self.max_retries = max_retries
        self.fallback_handler = fallback_handler
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """å¸¦é‡è¯•çš„äº‹ä»¶å¤„ç†"""
        self._execute_with_retry(
            "llm_start",
            lambda: self._handle_llm_start(serialized, prompts),
            kwargs
        )
    
    def _execute_with_retry(self, event_name: str, func, kwargs):
        """å¸¦é‡è¯•çš„æ‰§è¡Œ"""
        for attempt in range(self.max_retries):
            try:
                return func()
            except Exception as e:
                if attempt == self.max_retries - 1:
                    if self.fallback_handler:
                        return self._fallback_handler(event_name, e, kwargs)
                    raise e
                else:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 3. ç›‘æ§å’Œåˆ†æ

```python
class AnalyticsCallbackHandler(BaseCallbackHandler):
    """åˆ†æCallback Handler"""
    
    def __init__(self):
        super().__init__()
        self.analytics = {
            "event_counts": {},
            "performance_metrics": {},
            "error_rates": {}
        }
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """åˆ†æLLMå¼€å§‹äº‹ä»¶"""
        self._increment_event_count("llm_start")
        self._record_performance("llm_start", {"prompt_length": len(str(prompts))})
    
    def on_llm_error(self, error, **kwargs):
        """åˆ†æLLMé”™è¯¯äº‹ä»¶"""
        self._increment_event_count("llm_error")
        self._record_error("llm", type(error).__name__)
    
    def get_analytics_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = "=== æ‰§è¡Œåˆ†ææŠ¥å‘Š ===\n"
        report += f"äº‹ä»¶ç»Ÿè®¡: {self.analytics['event_counts']}\n"
        report += f"æ€§èƒ½æŒ‡æ ‡: {self.analytics['performance_metrics']}\n"
        report += f"é”™è¯¯ç‡: {self.analytics['error_rates']}\n"
        return report
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| Handlerç±»å‹ | å†…å­˜ä½¿ç”¨ | å“åº”æ—¶é—´ | å¼€å‘å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|-------------|---------|---------|-----------|----------|
| StreamingStdOutCallbackHandler | ä½ | å¿« | ä½ | è°ƒè¯•ã€å¼€å‘ |
| FileCallbackHandler | ä¸­ | ä¸­ | ä½ | æ—¥å¿—è®°å½• |
| AsyncCallbackHandler | ä¸­-é«˜ | å¿« | ä¸­ | å¼‚æ­¥åº”ç”¨ |
| CustomMetricsCallbackHandler | é«˜ | ä¸­-æ…¢ | é«˜ | ç”Ÿäº§ç›‘æ§ |

## ğŸ”— ç›¸å…³èµ„æº

- [LangChain Callbackså®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/modules/callbacks/)
- [Callbackå¼€å‘æŒ‡å—](https://python.langchain.com/docs/guides/development/callbacks/)
- [ç›‘æ§æœ€ä½³å®è·µ](https://python.langchain.com/docs/guides/productionization/monitoring)

---

ğŸ’¡ **å­¦ä¹ å»ºè®®**ï¼šå»ºè®®ä»åŸºç¡€çš„Callback Handlerå¼€å§‹å­¦ä¹ ï¼Œç„¶åæŒæ¡å¼‚æ­¥Callbackçš„å®ç°ï¼Œæœ€åå­¦ä¹ å¦‚ä½•è®¾è®¡å’Œå®ç°å¤æ‚çš„åˆ†æå‹Callbackç³»ç»Ÿã€‚